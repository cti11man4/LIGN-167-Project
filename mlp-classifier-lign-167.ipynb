{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport os\nimport plotly.graph_objects as go\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\ntorch.manual_seed(103)\ntorch.cuda.manual_seed(103)\nnp.random.seed(103)\n\ndeviceCount = torch.cuda.device_count()\nprint(deviceCount)\n\ncuda0 = None\nif deviceCount > 0:\n    print(torch.cuda.get_device_name(0))\n    cuda0 = torch.device('cuda:0')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:09.973268Z","iopub.execute_input":"2022-03-18T17:43:09.973725Z","iopub.status.idle":"2022-03-18T17:43:11.168436Z","shell.execute_reply.started":"2022-03-18T17:43:09.973644Z","shell.execute_reply":"2022-03-18T17:43:11.167540Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/history-of-philosophy/philosophy_data.csv')\ndf['y_expected'] = df['tokenized_txt']      # ensures that the new column can store a list datatype\n\ndrop_list = []\nfor i in range(df.shape[0]):\n    author = df.at[i,'author']\n    if author=='Aristotle':\n        df.at[i,'y_expected'] = torch.tensor([1,0,0,0,0])\n    elif author=='Plato':\n        df.at[i,'y_expected'] = torch.tensor([0,1,0,0,0])\n    elif author=='Hegel':\n        df.at[i,'y_expected'] = torch.tensor([0,0,1,0,0])\n    elif author=='Foucault':\n        df.at[i,'y_expected'] = torch.tensor([0,0,0,1,0])\n    elif author=='Heidegger':\n        df.at[i,'y_expected'] = torch.tensor([0,0,0,0,1])\n    else:\n        drop_list.append(i) \n        \ndf = df.drop(drop_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.169876Z","iopub.execute_input":"2022-03-18T17:43:11.170092Z","iopub.status.idle":"2022-03-18T17:43:11.302947Z","shell.execute_reply.started":"2022-03-18T17:43:11.170066Z","shell.execute_reply":"2022-03-18T17:43:11.300978Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# clean and tokenize each text entry\n\ndef clean_text(text):\n    \n    # lower case characters only\n    text = text.lower() \n    \n    # remove urls\n    text = re.sub('http\\S+', ' ', text)\n    \n    # only alphabets, spaces and apostrophes \n    text = re.sub(\"[^a-z' ]+\", ' ', text)\n    \n    # remove all apostrophes which are not used in word contractions\n    text = ' ' + text + ' '\n    text = re.sub(\"[^a-z]'|'[^a-z]\", ' ', text)\n    \n    return text.split()\n\n\ndf['tokenized_txt'] = df['sentence_str'].apply(lambda x: clean_text(x))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.303722Z","iopub.status.idle":"2022-03-18T17:43:11.304069Z","shell.execute_reply.started":"2022-03-18T17:43:11.303902Z","shell.execute_reply":"2022-03-18T17:43:11.303920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove entries still longer than 300 words\n\nentry_len = 300\n\ndrop_list = []\nfor i in range(df.shape[0]):\n    if i in df and len(df.at[i,'tokenized_txt']) >= entry_len:\n        drop_list.append(i)\n        \ndf = df.drop(drop_list).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.305105Z","iopub.status.idle":"2022-03-18T17:43:11.305408Z","shell.execute_reply.started":"2022-03-18T17:43:11.305251Z","shell.execute_reply":"2022-03-18T17:43:11.305267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove entries still longer than 100 words\n\nentry_len = 100\n\ndrop_list = []\nfor i in range(df.shape[0]):\n    if len(df.at[i,'tokenized_txt']) >= entry_len:\n        drop_list.append(i)\n        \ndf = df.drop(drop_list).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.306615Z","iopub.status.idle":"2022-03-18T17:43:11.306917Z","shell.execute_reply.started":"2022-03-18T17:43:11.306753Z","shell.execute_reply":"2022-03-18T17:43:11.306769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor i in df['tokenized_txt']:\n    if len(i) >100:\n        count += 1\n        \nprint(count)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.308258Z","iopub.status.idle":"2022-03-18T17:43:11.308624Z","shell.execute_reply.started":"2022-03-18T17:43:11.308413Z","shell.execute_reply":"2022-03-18T17:43:11.308430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load GloVe embeddings\n\ntext_embed_dim = 100                                        # changes the embedding dimension used\nglove_file = '../input/glove6b/glove.6B.{}d.txt'.format(text_embed_dim)    # defines the GloVe file path -- change if using a new encoding dataset\n\nembed_dict = {}\nwith open(glove_file) as f:\n    for line in f:\n        word, coefs = line.split(maxsplit=1)\n        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n        embed_dict[word] = coefs\n        \nprint(\"Found %s word vectors.\" % len(embed_dict))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.309624Z","iopub.status.idle":"2022-03-18T17:43:11.309915Z","shell.execute_reply.started":"2022-03-18T17:43:11.309760Z","shell.execute_reply":"2022-03-18T17:43:11.309776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select the first 2,000 entries for each of our philosophers\nnum_entries = 2000\n\nauthor_names = list(set(df['author']))\ndf_list = [df[df['author'] == author][:num_entries].reset_index(drop=True) for author in author_names]\ndf = pd.concat(df_list).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.311021Z","iopub.status.idle":"2022-03-18T17:43:11.311336Z","shell.execute_reply.started":"2022-03-18T17:43:11.311172Z","shell.execute_reply":"2022-03-18T17:43:11.311188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"entry_len = 100\n\n# replaces strings in an input sentence with word vectors\ndef embeddings(sent):\n    \n    # embedding includes an internal padding step\n    padding_vec = np.zeros(text_embed_dim)\n    out_list = [padding_vec] * entry_len\n    \n    # no padding step\n    #out_list = []\n    \n    for j in range (0, len(sent)):\n        if sent[j] in embed_dict:\n            out_list[j] = embed_dict[sent[j]]\n                     \n    return(torch.tensor(out_list))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.312485Z","iopub.status.idle":"2022-03-18T17:43:11.312776Z","shell.execute_reply.started":"2022-03-18T17:43:11.312621Z","shell.execute_reply":"2022-03-18T17:43:11.312636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this step applies embedding and padding to all tokens\ntokens_list = [embeddings(df['tokenized_txt'].values[i]) for i in range (num_entries*5)]","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.313812Z","iopub.status.idle":"2022-03-18T17:43:11.314103Z","shell.execute_reply.started":"2022-03-18T17:43:11.313947Z","shell.execute_reply":"2022-03-18T17:43:11.313963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is just list storage of labels for the same data \nidentity_list = [df['y_expected'].values[i] for i in range (5*num_entries)]","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.315229Z","iopub.status.idle":"2022-03-18T17:43:11.315578Z","shell.execute_reply.started":"2022-03-18T17:43:11.315382Z","shell.execute_reply":"2022-03-18T17:43:11.315398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffle dataset\nimport random as rand\n\n# zip to a combined reference\nto_shuffle = list(zip(tokens_list, identity_list))\n\n# shuffle combined reference\nrand.shuffle(to_shuffle)\n\n# unzip combined reference\ntokens_list, identity_list = zip(*to_shuffle)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.316341Z","iopub.status.idle":"2022-03-18T17:43:11.316669Z","shell.execute_reply.started":"2022-03-18T17:43:11.316504Z","shell.execute_reply":"2022-03-18T17:43:11.316521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# expand most common contractions in text entries\n\ncontractions  = { \"i'm\" : \"i am\", \"it's\" : \"it is\", \"don't\" : \"do not\", \"can't\" : \"cannot\", \n                  \"you're\" : \"you are\", \"that's\" : \"that is\", \"we're\" : \"we are\", \"i've\" : \"i have\", \n                  \"he's\" : \"he is\", \"there's\" : \"there is\", \"i'll\" : \"i will\", \"i'd\" : \"i would\", \n                  \"doesn't\" : \"does not\", \"what's\" : \"what is\", \"didn't\" : \"did not\", \n                  \"wasn't\" : \"was not\", \"hasn't\" : \"has not\", \"they're\" : \"they are\", \n                  \"let's\" : \"let us\", \"she's\" : \"she is\", \"isn't\" : \"is not\", \"ain't\" : \"not\", \n                  \"aren't\" : \"are not\", \"haven't\" : \"have not\", \"you'll\" : \"you will\", \n                  \"we've\" : \"we have\", \"you've\" : \"you have\", \"y'all\" : \"you all\", \n                  \"weren't\" : \"were not\", \"couldn't\" : \"could not\", \"would've\" : \"would have\", \n                  \"they've\" : \"they have\", \"they'll\" : \"they will\", \"you'd\" : \"you would\", \n                  \"they'd\" : \"they would\", \"it'll\" : \"it will\", \"where's\" : \"where is\", \n                  \"we'll\" : \"we will\", \"we'd\" : \"we would\", \"he'll\" : \"he will\", \"shouldn't\" : \"should not\", \n                  \"wouldn't\" : \"would not\", \"won't\" : \"will not\" }\n\n\ndef expand_contractions(words):\n    \n    for i in range(len(words)):\n        if words[i] in contractions:\n            words[i] = contractions[words[i]]\n            \n    return (' '.join(words)).split()\n\n\n# precautionary cleaning for any remaing apostrophes\ndef remove_apostrophes(words):\n    words = ' '.join(words)\n    words = re.sub(\"'\", '', words)\n    return words.split()\n\n\ndf['tokenized_txt'] = df['tokenized_txt'].apply(lambda words: expand_contractions(words))\ndf['tokenized_txt'] = df['tokenized_txt'].apply(lambda words: remove_apostrophes(words))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.318035Z","iopub.status.idle":"2022-03-18T17:43:11.318350Z","shell.execute_reply.started":"2022-03-18T17:43:11.318186Z","shell.execute_reply":"2022-03-18T17:43:11.318201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove most frequent stop words\n\nstop_words = [ 'the', 'a', 'in', 'to', 'of', 'i', 'and', 'is', 'you', 'for', 'on', 'it', 'my', 'that',\n               'with', 'are', 'at', 'by', 'this', 'have', 'from', 'be', 'was', 'do', 'will', 'as', 'up', \n               'me', 'am', 'so', 'we', 'your', 'has', 'when', 'an', 's', 'they', 'about', 'been', 'there',\n               'who', 'would', 'into', 'his', 'them', 'did', 'w', 'their', 'm', 'its', 'does', 'where', 'th',\n               'b', 'd', 'x', 'p', 'o', 'r', 'c', 'n', 'e', 'g', 'v', 'k', 'l', 'f', 'j', 'z', 'us', 'our',\n               'all', 'can', 'may' ] \n\ndef remove_stop_words(words):\n    result = []\n    for word in words:\n        if not (word in stop_words):\n            result.append(word)\n    return result\n\n# df['tokenized_txt'] = df['tokenized_txt'].apply(lambda words: remove_stop_words(words))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.319071Z","iopub.status.idle":"2022-03-18T17:43:11.319377Z","shell.execute_reply.started":"2022-03-18T17:43:11.319216Z","shell.execute_reply":"2022-03-18T17:43:11.319232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count words not in GloVe embeddings\n\nunknown_words = []\ntotal_words = 0\n\ndef find_unknown_words(words):\n    \n    global total_words\n    total_words = total_words + len(words)\n    \n    for word in words:\n        if not (word in embed_dict):\n            unknown_words.append(word)\n    \n    return words\n\n\ndf['tokenized_txt'].apply(lambda words: find_unknown_words(words))\n\nprint( f'{len(unknown_words)/total_words*100:5.2} % of words are unknown' )","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.322045Z","iopub.status.idle":"2022-03-18T17:43:11.322696Z","shell.execute_reply.started":"2022-03-18T17:43:11.322503Z","shell.execute_reply":"2022-03-18T17:43:11.322524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# analyze and create a table of remaining unknown words\n\ndef analyze_unknown_words(unknown_words):\n    \n    unknown_words = np.array(unknown_words)\n    (word, count) = np.unique(unknown_words, return_counts=True)\n    \n    word_freq = pd.DataFrame({'word': word, 'count': count}).sort_values('count', ascending=False)\n\n    fig = go.Figure(data=[go.Table(\n          header=dict(values=list(word_freq.columns),\n                    fill_color='paleturquoise',\n                    align='left'),\n          cells=dict(values=[word_freq['word'], word_freq['count']],\n                    fill_color='lavender',\n                    align='left'))\n          ])\n    fig.update_layout(width=300, height=300, margin={'b':0, 'l':0, 'r':0, 't':0, 'pad':0})\n    fig.show()\n        \nanalyze_unknown_words(unknown_words)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.323568Z","iopub.status.idle":"2022-03-18T17:43:11.323860Z","shell.execute_reply.started":"2022-03-18T17:43:11.323705Z","shell.execute_reply":"2022-03-18T17:43:11.323720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MLP definition\n\nclass MLPmodel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.softmax = nn.Softmax(dim=0)\n        \n        self.fc1 = nn.Linear(100, 100, False)\n        self.fc2 = nn.Linear(100, 200, False)\n        self.fc3 = nn.Linear(200, 5, False)\n        \n        self.fc4 = nn.Linear(500, 5, False)\n        \n    def forward(self, x):\n        \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = x.flatten()\n        x = F.relu(self.fc4(x))\n        return self.softmax(x)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.324831Z","iopub.status.idle":"2022-03-18T17:43:11.325123Z","shell.execute_reply.started":"2022-03-18T17:43:11.324966Z","shell.execute_reply":"2022-03-18T17:43:11.324982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(X_test, Y_test):\n    correct = 0\n    accuracy = 0\n    size = 0\n    for i in range(len(X_test)):\n        \n        pred = mlp_model(X_test[i].type(torch.FloatTensor))\n        current_label = Y_test[i]\n        \n        maxIdx = 0\n        for i in range(5):\n            if pred[i] > pred[maxIdx]:\n                maxIdx = i\n\n        if current_label[maxIdx] == 1:\n            correct += 1\n        \n        size += 1\n        \n    accuracy = correct / size\n    \n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.326003Z","iopub.status.idle":"2022-03-18T17:43:11.326308Z","shell.execute_reply.started":"2022-03-18T17:43:11.326147Z","shell.execute_reply":"2022-03-18T17:43:11.326162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-4\n\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.Adam(mlp_model.parameters(), lr=lr)\n\noutput = [[],[]]\nauthor_list = [tokens_list, identity_list]\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(tokens_list, identity_list, test_size=0.2)\ntrain_list = [X_train, Y_train]\ntest_list = [X_test, Y_test]","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.327355Z","iopub.status.idle":"2022-03-18T17:43:11.327685Z","shell.execute_reply.started":"2022-03-18T17:43:11.327518Z","shell.execute_reply":"2022-03-18T17:43:11.327538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 30\nbatch_size = 20\ncurrent_batch = 0\nrun_number = 0\n\nvalidation_loss = []\nvalidation_accuracy = []\ntrain_loss = []\ntrain_accuracy = []\n\nmlp_model = MLPmodel()\n\nlr = 1e-4\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.Adam(mlp_model.parameters(), lr=lr)\n\nfor epoch in range(num_epochs):\n    current_loss = 0\n    \n    train_correct = 0\n    samples = 0\n    \n    for i in range(batch_size):\n        sample_index = (i + epoch*batch_size) % len(train_list)\n        \n        pred = mlp_model(train_list[0][sample_index].type(torch.FloatTensor))\n        current_loss += loss_fn(pred, train_list[1][i].type(torch.FloatTensor))\n        run_number += 1\n    \n    train_loss.append(current_loss)\n    \n    optimizer.zero_grad()\n    current_loss.backward()\n    optimizer.step()\n    \n    val_accuracy = validate(X_test, Y_test)\n    validation_accuracy.append(val_accuracy)\n\n    train_accuracy.append(validate(X_train, Y_train))\n    train_loss.append(current_loss)\n    \n    if (epoch % 5 == 0):\n        print(\"Epoch: {}\".format(epoch+1))\n        print(f'Train Loss: {current_loss}')\n        print(f'Train Accuracy: {train_accuracy[epoch]}')\n        print(f'Validation Accuracy: {validation_accuracy[epoch]}')\n        print('')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.328463Z","iopub.status.idle":"2022-03-18T17:43:11.328770Z","shell.execute_reply.started":"2022-03-18T17:43:11.328601Z","shell.execute_reply":"2022-03-18T17:43:11.328623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(train_accuracy, label = 'Training Accuracy')\nplt.plot(validation_accuracy, label = \"Validation Accuracy\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Multi-layer Perceptron Accuracy over Time\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T17:43:11.329939Z","iopub.status.idle":"2022-03-18T17:43:11.330251Z","shell.execute_reply.started":"2022-03-18T17:43:11.330079Z","shell.execute_reply":"2022-03-18T17:43:11.330102Z"},"trusted":true},"execution_count":null,"outputs":[]}]}